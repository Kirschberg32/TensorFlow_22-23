{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6171350-bf14-4e11-8d40-03df2b31a812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241AA8B9160> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241AA8B9160>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241AA8B9160> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241AA8B9160>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241AA8B9160> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241AA8B9160>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A95CEB80> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A95CEB80>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A95CEB80> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A95CEB80>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A95CEB80> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A95CEB80>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A8D644C0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A8D644C0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A8D644C0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A8D644C0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A8D644C0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A8D644C0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241AA6BFE50> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241AA6BFE50>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241AA6BFE50> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241AA6BFE50>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241AA6BFE50> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241AA6BFE50>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x000002418E1F1280> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x000002418E1F1280>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x000002418E1F1280> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x000002418E1F1280>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x000002418E1F1280> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x000002418E1F1280>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A95CE5E0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A95CE5E0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A95CE5E0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A95CE5E0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A95CE5E0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A95CE5E0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A95CE820> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A95CE820>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A95CE820> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A95CE820>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A95CE820> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A95CE820>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A94F30D0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A94F30D0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A94F30D0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A94F30D0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A94F30D0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A94F30D0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A94F3C10> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A94F3C10>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A94F3C10> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A94F3C10>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A94F3C10> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A94F3C10>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A94F3A60> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A94F3A60>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A94F3A60> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A94F3A60>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function data_preprocess.<locals>.<lambda> at 0x00000241A94F3A60> and will run it as-is.\n",
      "Cause: could not parse the source code of <function data_preprocess.<locals>.<lambda> at 0x00000241A94F3A60>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda img, target: (tf.cast(img, tf.float32), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (((img / 128.0) - 1.0), target))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.one_hot(target, depth=sequence)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.where((tf.math.floormod(range_vals, 2) == 0), target, (- target))))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (img, tf.math.cumsum(target)))\n",
      "# coding=utf-8\n",
      "(lambda img, target: (augment(img), target))\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\eosan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\eosan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\eosan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\OneDrive\\Dokumente\\GitHub\\TensorFlow_22-23\\Homework07\\model.py\", line 173, in train_step\n        output = self(sequence, training=True)\n    File \"C:\\Users\\eosan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\eosan\\AppData\\Local\\Temp\\__autograph_generated_fileov98x0ys.py\", line 11, in tf__call\n        x = ag__.converted_call(ag__.ld(self).conv_block2, (ag__.ld(x),), dict(training=ag__.ld(training)), fscope)\n    File \"C:\\Users\\eosan\\AppData\\Local\\Temp\\__autograph_generated_filed9saikoh.py\", line 75, in tf__call\n        x = ag__.converted_call(ag__.ld(self).pool, (ag__.ld(x),), None, fscope)\n\n    AttributeError: Exception encountered when calling layer \"my_lstm_model_3\" \"                 f\"(type MyLSTMModel).\n    \n    in user code:\n    \n        File \"d:\\OneDrive\\Dokumente\\GitHub\\TensorFlow_22-23\\Homework07\\model.py\", line 158, in call  *\n            x = self.conv_block2(x, training = training)\n        File \"C:\\Users\\eosan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\eosan\\AppData\\Local\\Temp\\__autograph_generated_filed9saikoh.py\", line 75, in tf__call\n            x = ag__.converted_call(ag__.ld(self).pool, (ag__.ld(x),), None, fscope)\n    \n        AttributeError: Exception encountered when calling layer \"my_cnn_block_7\" \"                 f\"(type MyCNNBlock).\n        \n        in user code:\n        \n            File \"d:\\OneDrive\\Dokumente\\GitHub\\TensorFlow_22-23\\Homework07\\model.py\", line 117, in call  *\n                x = self.pool(x)\n        \n            AttributeError: 'MyCNNBlock' object has no attribute 'pool'\n        \n        \n        Call arguments received by layer \"my_cnn_block_7\" \"                 f\"(type MyCNNBlock):\n          • input=tf.Tensor(shape=(None, 14, 14, 24), dtype=float32)\n          • training=True\n    \n    \n    Call arguments received by layer \"my_lstm_model_3\" \"                 f\"(type MyLSTMModel):\n      • x=tf.Tensor(shape=(None, 28, 28, 1), dtype=float32)\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 28\u001b[0m\n\u001b[0;32m     24\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer \u001b[39m=\u001b[39m optimizer, loss\u001b[39m=\u001b[39mloss)\n\u001b[0;32m     26\u001b[0m logging_callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mTensorBoard(log_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./logs/run1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(training_data, validation_data \u001b[39m=\u001b[39;49m val_data, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size, callbacks\u001b[39m=\u001b[39;49m[logging_callback])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_5dfx5w2.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\OneDrive\\Dokumente\\GitHub\\TensorFlow_22-23\\Homework07\\model.py:173\u001b[0m, in \u001b[0;36mMyLSTMModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    171\u001b[0m sequence, label \u001b[39m=\u001b[39m data\n\u001b[0;32m    172\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m--> 173\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(sequence, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    174\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size(label, output, regularization_losses\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses)\n\u001b[0;32m    175\u001b[0m gradients \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainable_variables)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileov98x0ys.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, x, training)\u001b[0m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m     10\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mconv_block1, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(training)), fscope)\n\u001b[1;32m---> 11\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mconv_block2, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(training)), fscope)\n\u001b[0;32m     12\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mtimedistributed, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     13\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mrnn_buffer, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filed9saikoh.py:75\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, input, training)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m     74\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt((ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mextra_layer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m), if_body_2, else_body_2, get_state_3, set_state_3, (\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39m1\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mpool, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     76\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\eosan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\eosan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\eosan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\OneDrive\\Dokumente\\GitHub\\TensorFlow_22-23\\Homework07\\model.py\", line 173, in train_step\n        output = self(sequence, training=True)\n    File \"C:\\Users\\eosan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\eosan\\AppData\\Local\\Temp\\__autograph_generated_fileov98x0ys.py\", line 11, in tf__call\n        x = ag__.converted_call(ag__.ld(self).conv_block2, (ag__.ld(x),), dict(training=ag__.ld(training)), fscope)\n    File \"C:\\Users\\eosan\\AppData\\Local\\Temp\\__autograph_generated_filed9saikoh.py\", line 75, in tf__call\n        x = ag__.converted_call(ag__.ld(self).pool, (ag__.ld(x),), None, fscope)\n\n    AttributeError: Exception encountered when calling layer \"my_lstm_model_3\" \"                 f\"(type MyLSTMModel).\n    \n    in user code:\n    \n        File \"d:\\OneDrive\\Dokumente\\GitHub\\TensorFlow_22-23\\Homework07\\model.py\", line 158, in call  *\n            x = self.conv_block2(x, training = training)\n        File \"C:\\Users\\eosan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\eosan\\AppData\\Local\\Temp\\__autograph_generated_filed9saikoh.py\", line 75, in tf__call\n            x = ag__.converted_call(ag__.ld(self).pool, (ag__.ld(x),), None, fscope)\n    \n        AttributeError: Exception encountered when calling layer \"my_cnn_block_7\" \"                 f\"(type MyCNNBlock).\n        \n        in user code:\n        \n            File \"d:\\OneDrive\\Dokumente\\GitHub\\TensorFlow_22-23\\Homework07\\model.py\", line 117, in call  *\n                x = self.pool(x)\n        \n            AttributeError: 'MyCNNBlock' object has no attribute 'pool'\n        \n        \n        Call arguments received by layer \"my_cnn_block_7\" \"                 f\"(type MyCNNBlock):\n          • input=tf.Tensor(shape=(None, 14, 14, 24), dtype=float32)\n          • training=True\n    \n    \n    Call arguments received by layer \"my_lstm_model_3\" \"                 f\"(type MyLSTMModel):\n      • x=tf.Tensor(shape=(None, 28, 28, 1), dtype=float32)\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "import get_data\n",
    "from model import MyLSTMModel\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "epochs = 1\n",
    "batch_size = 64\n",
    "sequence = 6\n",
    "lstm_units = 12\n",
    "\n",
    "# get and prepare data and model\n",
    "(training_data, val_data ) , ds_info = get_data.load_data(False) # True\n",
    "#training_data = training_data.take(2000) # \n",
    "training_data = get_data.data_preprocess(training_data, batch_size = batch_size,sequence = sequence) # augment should be used on train data only\n",
    "val_data = get_data.data_preprocess(val_data, batch_size = batch_size, sequence = sequence)\n",
    "\n",
    "model = MyLSTMModel(input_shape = (batch_size, sequence, 28,28,1), lstm_units = lstm_units, output_units = 1)\n",
    "\n",
    "# compile the model (here, adding a loss function and an optimizer)\n",
    "model.compile(optimizer = optimizer, loss=loss)\n",
    "\n",
    "logging_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs/run1\")\n",
    "\n",
    "history = model.fit(training_data, validation_data = val_data, epochs=epochs, batch_size=batch_size, callbacks=[logging_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e40d630-0c92-4bdf-aab8-3041b744d2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 6), dtype=tf.float32, name=None))>\n",
      "(<tf.Tensor: shape=(64, 28, 28, 1), dtype=float32, numpy=\n",
      "array([[[[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]]],\n",
      "\n",
      "\n",
      "       [[[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]]],\n",
      "\n",
      "\n",
      "       [[[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]]],\n",
      "\n",
      "\n",
      "       [[[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]]],\n",
      "\n",
      "\n",
      "       [[[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]],\n",
      "\n",
      "        [[-1.],\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         ...,\n",
      "         [-1.],\n",
      "         [-1.],\n",
      "         [-1.]]]], dtype=float32)>, <tf.Tensor: shape=(64, 6), dtype=float32, numpy=\n",
      "array([[ 0.,  0.,  0.,  0.,  1.,  1.],\n",
      "       [ 0.,  0.,  0., -1., -1., -1.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., -1., -1., -1.],\n",
      "       [ 0.,  0.,  0., -1., -1., -1.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  1.,  1.,  1.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0., -1.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 1.,  1.,  1.,  1.,  1.,  1.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  1.,  1.,  1.],\n",
      "       [ 0.,  0.,  0.,  0.,  1.,  1.],\n",
      "       [ 0., -1., -1., -1., -1., -1.],\n",
      "       [ 0.,  0.,  1.,  1.,  1.,  1.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., -1., -1., -1.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  1.,  1.,  1.],\n",
      "       [ 0.,  0.,  0.,  0.,  1.,  1.],\n",
      "       [ 0.,  0.,  0.,  0.,  1.,  1.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0., -1., -1., -1., -1., -1.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 1.,  1.,  1.,  1.,  1.,  1.],\n",
      "       [ 0., -1., -1., -1., -1., -1.],\n",
      "       [ 0.,  0.,  0.,  0.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.,  1.,  1.],\n",
      "       [ 0.,  0.,  0., -1., -1., -1.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 1.,  1.,  1.,  1.,  1.,  1.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0., -1.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  1.,  1.,  1.],\n",
      "       [ 0.,  0.,  1.,  1.,  1.,  1.],\n",
      "       [ 0.,  0.,  0.,  0.,  1.,  1.],\n",
      "       [ 0.,  0.,  0., -1., -1., -1.],\n",
      "       [ 0.,  0.,  0., -1., -1., -1.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  1.,  1.,  1.],\n",
      "       [ 0.,  0.,  1.,  1.,  1.,  1.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  1.,  1.,  1.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  1.,  1.],\n",
      "       [ 0.,  0.,  0.,  0.,  1.,  1.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  1.,  1.],\n",
      "       [ 0.,  0.,  0., -1., -1., -1.],\n",
      "       [ 0.,  0.,  1.,  1.,  1.,  1.],\n",
      "       [ 0.,  0.,  1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.,  1.,  1.]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "print(training_data)\n",
    "\n",
    "for i in training_data:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd28ec9b-594f-4afe-8e8a-d7433a4ad494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97cc6ec-d5e2-4d2d-8781-b08abafa332b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7c5966-d51c-479d-9e99-b29502d30f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc1d0feb4753dbff4e13108373da06d3c8e279e8b23ae8a2a94c3e58989306d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
